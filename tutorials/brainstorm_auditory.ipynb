{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd359302",
   "metadata": {},
   "source": [
    "# Brainstorm Auditory Dataset with invertmeeg\n",
    "\n",
    "This tutorial demonstrates how to use **invertmeeg** solvers on real MEG data from\n",
    "the [Brainstorm auditory dataset](https://neuroimage.usc.edu/brainstorm/DatasetAuditory).\n",
    "The dataset contains auditory evoked fields (AEFs) recorded with a 275-channel CTF MEG\n",
    "system during a standard/deviant oddball paradigm.\n",
    "\n",
    "We preprocess the data using MNE-Python and then compute inverse solutions with three\n",
    "solvers from different algorithmic families:\n",
    "\n",
    "| Solver | Family | Key idea |\n",
    "|---|---|---|\n",
    "| **eLORETA** | Minimum Norm | Iteratively reweighted minimum-norm with exact localization |\n",
    "| **LAURA** | Minimum Norm | Spatially weighted source priors from local autoregression |\n",
    "| **ESMV** | Beamformer | Eigenspace-projected minimum-variance spatial filter |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bccddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from mne import combine_evoked\n",
    "from mne.datasets.brainstorm import bst_auditory\n",
    "from mne.io import read_raw_ctf\n",
    "\n",
    "from invert import Solver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec864ca7",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d2bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = bst_auditory.data_path()\n",
    "\n",
    "subject = \"bst_auditory\"\n",
    "subjects_dir = data_path / \"subjects\"\n",
    "\n",
    "raw_fname1 = data_path / \"MEG\" / subject / \"S01_AEF_20131218_01.ds\"\n",
    "raw_fname2 = data_path / \"MEG\" / subject / \"S01_AEF_20131218_02.ds\"\n",
    "erm_fname = data_path / \"MEG\" / subject / \"S01_Noise_20131218_01.ds\"\n",
    "\n",
    "# Load and concatenate both runs\n",
    "raw = read_raw_ctf(raw_fname1)\n",
    "n_times_run1 = raw.n_times\n",
    "mne.io.concatenate_raws([raw, read_raw_ctf(raw_fname2)], on_mismatch=\"ignore\")\n",
    "raw_erm = read_raw_ctf(erm_fname)\n",
    "\n",
    "raw.set_channel_types({\"HEOG\": \"eog\", \"VEOG\": \"eog\", \"ECG\": \"ecg\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f8fb99",
   "metadata": {},
   "source": [
    "### Annotations and artifact projections\n",
    "\n",
    "We load pre-labeled artifact annotations (bad segments and saccades) and compute\n",
    "SSP projectors to suppress ocular artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8d5678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse annotations from CSV files\n",
    "annotations_df = pd.DataFrame()\n",
    "for idx in [1, 2]:\n",
    "    csv_fname = data_path / \"MEG\" / \"bst_auditory\" / f\"events_bad_0{idx}.csv\"\n",
    "    df = pd.read_csv(csv_fname, header=None,\n",
    "                     names=[\"onset\", \"duration\", \"id\", \"label\"])\n",
    "    df[\"onset\"] += n_times_run1 * (idx - 1)\n",
    "    annotations_df = pd.concat([annotations_df, df], axis=0)\n",
    "\n",
    "saccades_events = df[df[\"label\"] == \"saccade\"].values[:, :3].astype(int)\n",
    "\n",
    "annotations = mne.Annotations(\n",
    "    annotations_df[\"onset\"].values / raw.info[\"sfreq\"],\n",
    "    annotations_df[\"duration\"].values / raw.info[\"sfreq\"],\n",
    "    annotations_df[\"label\"].values,\n",
    ")\n",
    "raw.set_annotations(annotations)\n",
    "\n",
    "# Saccade and EOG projectors\n",
    "saccade_epochs = mne.Epochs(raw, saccades_events, 1, 0.0, 0.5,\n",
    "                            preload=True, baseline=(None, None),\n",
    "                            reject_by_annotation=False)\n",
    "projs_saccade = mne.compute_proj_epochs(saccade_epochs, n_mag=1, n_eeg=0,\n",
    "                                        desc_prefix=\"saccade\")\n",
    "proj_fname = data_path / \"MEG\" / \"bst_auditory\" / \"bst_auditory-eog-proj.fif\"\n",
    "projs_eog = mne.read_proj(proj_fname)[0]\n",
    "raw.add_proj(projs_saccade)\n",
    "raw.add_proj(projs_eog)\n",
    "\n",
    "del saccade_epochs, saccades_events, projs_eog, projs_saccade, annotations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c45d27",
   "metadata": {},
   "source": [
    "### Epoching and averaging\n",
    "\n",
    "We correct the trigger-to-sound delay using the analog audio channel, reject\n",
    "bad epochs, and average the standard and deviant conditions separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0627dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin, tmax = -0.1, 0.5\n",
    "event_id = dict(standard=1, deviant=2)\n",
    "reject = dict(mag=4e-12, eog=250e-6)\n",
    "\n",
    "# Find events and correct trigger delay\n",
    "events = mne.find_events(raw, stim_channel=\"UPPT001\")\n",
    "sound_data = raw[raw.ch_names.index(\"UADC001-4408\")][0][0]\n",
    "onsets = np.where(np.abs(sound_data) > 2.0 * np.std(sound_data))[0]\n",
    "min_diff = int(0.5 * raw.info[\"sfreq\"])\n",
    "diffs = np.concatenate([[min_diff + 1], np.diff(onsets)])\n",
    "onsets = onsets[diffs > min_diff]\n",
    "assert len(onsets) == len(events)\n",
    "print(f\"Trigger delay removed \"\n",
    "      f\"(\\u03bc \\u00b1 \\u03c3): {np.mean(1000.0 * (events[:, 0] - onsets) / raw.info['sfreq']):0.1f}\"\n",
    "      f\" \\u00b1 {np.std(1000.0 * (events[:, 0] - onsets) / raw.info['sfreq']):0.1f} ms\")\n",
    "events[:, 0] = onsets\n",
    "\n",
    "# Mark bad channels\n",
    "raw.info[\"bads\"] = [\"MLO52-4408\", \"MRT51-4408\", \"MLO42-4408\", \"MLO43-4408\"]\n",
    "\n",
    "# Create epochs\n",
    "epochs = mne.Epochs(raw, events, event_id, tmin, tmax,\n",
    "                    picks=[\"meg\", \"eog\"], baseline=(None, 0),\n",
    "                    reject=reject, preload=False, proj=True)\n",
    "epochs.drop_bad()\n",
    "epochs.set_annotations(None)\n",
    "\n",
    "# Balance standard trials and resample\n",
    "epochs_standard = mne.concatenate_epochs(\n",
    "    [epochs[\"standard\"][range(40)], epochs[\"standard\"][182:222]]\n",
    ")\n",
    "epochs_standard.load_data().resample(600, npad=\"auto\")\n",
    "epochs_deviant = epochs[\"deviant\"].load_data()\n",
    "epochs_deviant.resample(600, npad=\"auto\")\n",
    "\n",
    "# Average and low-pass filter\n",
    "evoked_std = epochs_standard.average()\n",
    "evoked_dev = epochs_deviant.average()\n",
    "for evoked in (evoked_std, evoked_dev):\n",
    "    evoked.filter(l_freq=None, h_freq=40.0, fir_design=\"firwin\")\n",
    "\n",
    "del epochs, epochs_standard, epochs_deviant, sound_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0986073d",
   "metadata": {},
   "source": [
    "## 2. Evoked Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126a3e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked_std.plot(window_title=\"Standard\", gfp=True, time_unit=\"s\")\n",
    "evoked_dev.plot(window_title=\"Deviant\", gfp=True, time_unit=\"s\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1684f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked_difference = combine_evoked([evoked_dev, evoked_std], weights=[1, -1])\n",
    "evoked_difference.plot(window_title=\"Difference (Deviant - Standard)\",\n",
    "                       gfp=True, time_unit=\"s\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a379f8b",
   "metadata": {},
   "source": [
    "## 3. Forward Model and Noise Covariance\n",
    "\n",
    "We create a forward solution using an ico4 source space and estimate a noise covariance\n",
    "matrix from the empty-room recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deb05e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise covariance from empty-room recording\n",
    "cov = mne.compute_raw_covariance(raw_erm, reject=dict(mag=4e-12))\n",
    "del raw_erm, raw\n",
    "\n",
    "# Create source space at ico4 resolution\n",
    "src = mne.setup_source_space(subject, spacing=\"ico4\", subjects_dir=subjects_dir,\n",
    "                             add_dist=\"patch\")\n",
    "print(f\"Source space: {sum(s['nuse'] for s in src)} sources\")\n",
    "\n",
    "# Create BEM model and solution (single layer for MEG)\n",
    "conductivity = (0.3,)  # single layer for MEG\n",
    "model = mne.make_bem_model(subject=subject, subjects_dir=subjects_dir,\n",
    "                           conductivity=conductivity)\n",
    "bem = mne.make_bem_solution(model)\n",
    "\n",
    "# Compute forward solution\n",
    "fwd = mne.make_forward_solution(evoked_dev.info, trans=\"fsaverage\",\n",
    "                                src=src, bem=bem, eeg=False, mindist=5.0)\n",
    "print(f\"Forward solution: {fwd['sol']['data'].shape[1]} sources, \"\n",
    "      f\"{fwd['sol']['data'].shape[0]} channels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ket39xufnul",
   "metadata": {},
   "source": [
    "### Whiten the data using noise covariance\n",
    "\n",
    "Pre-whitening the data using the noise covariance matrix decorrelates sensor noise\n",
    "and normalizes channel variances. This improves source localization accuracy,\n",
    "especially for methods that assume white (identity) noise covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pw41dqehk7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute whitener from noise covariance\n",
    "# Pick only magnetometers (CTF system has only axial gradiometers, which MNE treats as \"mag\")\n",
    "picks = mne.pick_types(evoked_dev.info, meg=\"mag\", eeg=False, exclude=\"bads\")\n",
    "ch_names_evoked = [evoked_dev.ch_names[i] for i in picks]\n",
    "\n",
    "# Find intersection of channels in evoked and covariance\n",
    "ch_names_cov = cov.ch_names\n",
    "ch_names_meg = [ch for ch in ch_names_evoked if ch in ch_names_cov]\n",
    "\n",
    "print(f\"Evoked MEG channels: {len(ch_names_evoked)}\")\n",
    "print(f\"Covariance channels: {len(ch_names_cov)}\")\n",
    "print(f\"Common channels (used for whitening): {len(ch_names_meg)}\")\n",
    "\n",
    "# Pick the common channels from the covariance matrix\n",
    "cov_picked = mne.cov.pick_channels_cov(cov, ch_names_meg)\n",
    "\n",
    "# Compute whitener with regularization (rank=\"info\" uses the info to determine rank)\n",
    "# Create a temporary info with only the selected channels\n",
    "info_picked = mne.pick_info(evoked_dev.info, mne.pick_channels(evoked_dev.ch_names, ch_names_meg))\n",
    "whitener, _ = mne.cov.compute_whitener(cov_picked, info_picked, rank=\"info\", )\n",
    "\n",
    "print(f\"Whitener shape: {whitener.shape}\")\n",
    "print(f\"Whitener condition number: {np.linalg.cond(whitener):.1f}\")\n",
    "\n",
    "# Apply whitening to evoked data\n",
    "evoked_std_white = evoked_std.copy().pick(ch_names_meg)\n",
    "evoked_dev_white = evoked_dev.copy().pick(ch_names_meg)\n",
    "\n",
    "evoked_std_white.data = whitener @ evoked_std_white.data\n",
    "evoked_dev_white.data = whitener @ evoked_dev_white.data\n",
    "\n",
    "# Also whiten the forward model leadfield for consistency\n",
    "fwd_white = mne.convert_forward_solution(fwd, force_fixed=False)\n",
    "fwd_white = mne.pick_channels_forward(fwd_white, ch_names_meg)\n",
    "fwd_white[\"sol\"][\"data\"] = whitener @ fwd_white[\"sol\"][\"data\"]\n",
    "\n",
    "print(f\"Whitened evoked data shape: {evoked_dev_white.data.shape}\")\n",
    "print(f\"Whitened forward model: {fwd_white['sol']['data'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b755f3d4",
   "metadata": {},
   "source": [
    "## 4. Source Reconstruction with invertmeeg\n",
    "\n",
    "Every solver in **invertmeeg** follows the same two-step API:\n",
    "\n",
    "```python\n",
    "solver = Solver(\"name\")\n",
    "solver.make_inverse_operator(fwd, evoked)   # fit\n",
    "stc = solver.apply_inverse_operator(evoked) # apply\n",
    "```\n",
    "\n",
    "We apply each solver to the **deviant** evoked response and plot the result\n",
    "on the inflated cortical surface at the time of peak activation.\n",
    "\n",
    "Note: the forward model has ~8k fixed-orientation sources. The solvers below\n",
    "are all fast enough to handle this comfortably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d36f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared plotting helper\n",
    "def plot_source_estimate(stc, title):\n",
    "    stc.subject = subject\n",
    "    peak_time = 0.1  # for auditory response\n",
    "    brain = stc.plot(\n",
    "        subjects_dir=subjects_dir,\n",
    "        subject=subject,\n",
    "        surface=\"inflated\",\n",
    "        # hemi=\"lh\",\n",
    "        hemi=\"both\",\n",
    "        cortex=\"low_contrast\",\n",
    "        initial_time=peak_time,\n",
    "        time_unit=\"s\",\n",
    "        time_viewer=True,\n",
    "        brain_kwargs=dict(title=title),\n",
    "        size=(800, 400),\n",
    "    )\n",
    "    # brain = stc.plot(\n",
    "    #     subjects_dir=subjects_dir,\n",
    "    #     subject=subject,\n",
    "    #     surface=\"inflated\",\n",
    "    #     time_viewer=False,\n",
    "    #     hemi=\"lh\",\n",
    "    #     initial_time=0.1,\n",
    "    #     time_unit=\"s\",\n",
    "    # )\n",
    "    return brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8a8bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = mne.minimum_norm.make_inverse_operator(evoked_std.info, fwd, cov)\n",
    "snr = 3.0\n",
    "lambda2 = 1.0 / snr**2\n",
    "\n",
    "\n",
    "stc_standard = mne.minimum_norm.apply_inverse(evoked_std, inv, lambda2, \"dSPM\")\n",
    "brain = stc_standard.plot(\n",
    "    subjects_dir=subjects_dir,\n",
    "    subject=subject,\n",
    "    surface=\"inflated\",\n",
    "    time_viewer=False,\n",
    "    hemi=\"lh\",\n",
    "    initial_time=0.1,\n",
    "    time_unit=\"s\",\n",
    ")\n",
    "del stc_standard, brain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c24e77d",
   "metadata": {},
   "source": [
    "### dSPM\n",
    "\n",
    "Dynamic Statistical Parametric Mapping (dSPM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e353c596",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_dspm = Solver(\"dSPM\", depth_weighting=0.5)\n",
    "solver_dspm.make_inverse_operator(fwd_white, evoked_std_white.copy().crop(0.05, 0.25))\n",
    "stc_dspm = solver_dspm.apply_inverse_operator(evoked_std_white)\n",
    "plot_source_estimate(stc_dspm, \"dSPM\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b63574",
   "metadata": {},
   "source": [
    "### ESMV\n",
    "\n",
    "Eigenspace-based Minimum Variance beamformer. Projects the data into the\n",
    "signal subspace before applying a minimum-variance spatial filter, improving\n",
    "robustness against interference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e421907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_esmv = Solver(\"esmv\")\n",
    "solver_esmv.make_inverse_operator(fwd_white, evoked_std_white.copy().crop(0.05, 0.25))\n",
    "stc_esmv = solver_esmv.apply_inverse_operator(evoked_std_white)\n",
    "plot_source_estimate(stc_esmv, \"ESMV\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200fdb4a",
   "metadata": {},
   "source": [
    "### APSE\n",
    "Adaptive Patch Source Estimation (APSE) - A hybrid inverse solution technique\n",
    "that combines the strengths of beamformers, subspace methods, and sparse\n",
    "Bayesian approaches for patch-sized source reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3527d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_esmv = Solver(\"apse\")\n",
    "solver_esmv.make_inverse_operator(fwd_white, evoked_std_white)#.copy().crop(0.05, 0.2))\n",
    "stc_esmv = solver_esmv.apply_inverse_operator(evoked_std_white)\n",
    "plot_source_estimate(stc_esmv, \"Adaptive Patch Source Estimation\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
